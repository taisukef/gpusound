<!DOCTYPE html>
<!-- https://qiita.com/gaziya5/items/e58f8c1fce3f3f227ca7 -->
<html><head><meat charset="utf-8"></head>
<body>
<script id="vs" type="x-shader/x-vertex">
#version 300 es
uniform float sampleRate; 
out vec2 gain; 

#define BPM 120.
#define A (15. / BPM)
#define B (240. / BPM)

#define C3  60
#define Scale C3+int[](0, 2, 4, 5, 7, 9, 11)

float distortion(float gain, float d) {
    return clamp(gain * d, -1.0, 1.0);
}

float sound(float f, float time) {
    return distortion(sin(6.2831*f*time), 2.5) *exp(-time*3.0);
}

float note2freq(int n) {
    return 440.0*exp2((float(n)-69.0)/12.0);
}

int sequenceOrder(int s,float time) {
    int n =-1;
    for(int i=0;i<=int(mod(time,B)/A);i++){
        if((s>>i&1)==1)n++;
    }
    return n;
}

float sequenceTime(int s,float time) {
  float n = mod(time,A);
  for (int i=0;i<16;i++){
    if((s>>(int(time/A)-i)%16&1)==1)break;
    n+=A;
  }
  return n;
}

vec2 mainSound(float time) {
    int b = int(time / B) % 8;
    int s = int[](0x1111, 0x0111, 0x0101, 0x5555)[
                int[](0,1,0,1,2,2,3,1)[b]
            ];
    int o = sequenceOrder(s, time);
    int i = int[](1672, 10, 2842, 156, 0, 0, 7152192, 10)[b] >> (o * 3) & 7; // the frog song
    int n = Scale[i];
    float t = sequenceTime(s, time);
    return vec2(sound(note2freq(n),t));
}

void main() {
  float time = float(gl_VertexID) / sampleRate;
  gain = mainSound(time);
}

</script>

<script id="fs" type="x-shader/x-fragment">
#version 300 es
void main() {}
</script>

<button id="btn">start</button>
<script type="module">
btn.onclick = () => {
  const duration = 38; // sec
  const AudioContext = window.AudioContext || window.webkitAudioContext;
  const audio = new AudioContext();
  const sampleRate = audio.sampleRate;
  const bufferSize = (audio.sampleRate * duration) >> 1;
  const audioBuffer = audio.createBuffer(2, bufferSize, audio.sampleRate);
  const node = audio.createBufferSource();
  const canvas = document.createElement("canvas");
  const gl = canvas.getContext("webgl2") || canvas.getContext("experimental-webgl2");
  const compileShader = (prog, src, type) => {
    const sh = gl.createShader(type);
    gl.shaderSource(sh, src.replace(/^\n/, ""));
    gl.compileShader(sh);
    if (!gl.getShaderParameter(sh, gl.COMPILE_STATUS)) {
      alert(gl.getShaderInfoLog(sh));
    } 
    gl.attachShader(prog, sh);
    gl.deleteShader(sh);
  };
  const program = gl.createProgram();
  compileShader(program, vs.text, gl.VERTEX_SHADER);
  compileShader(program, fs.text, gl.FRAGMENT_SHADER);
  gl.transformFeedbackVaryings(program, ['gain'], gl.SEPARATE_ATTRIBS);
  gl.linkProgram(program);
  gl.useProgram(program); 
  gl.uniform1f(gl.getUniformLocation(program, "sampleRate"), sampleRate); 
  const vbos = [gl.createBuffer(),gl.createBuffer()];
  for (let i = 0; i < 2; i++) {
    gl.bindBuffer(gl.ARRAY_BUFFER, vbos[i]);
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(bufferSize * 2), gl.STATIC_DRAW);
  }
  gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, vbos[0]);
  gl.enable(gl.RASTERIZER_DISCARD);
  gl.beginTransformFeedback(gl.POINTS);
  gl.drawArrays(gl.POINTS, 0, bufferSize);
  gl.endTransformFeedback();
  gl.disable(gl.RASTERIZER_DISCARD);
  gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, null);
  gl.bindBuffer(gl.ARRAY_BUFFER, vbos[0]);
  const aryBuffer = new ArrayBuffer(bufferSize * (4 * 2));
  const dataView = new DataView(aryBuffer);
  gl.getBufferSubData(gl.ARRAY_BUFFER, 0, dataView); 
  const buf = new Float32Array(aryBuffer);
  const data0 = audioBuffer.getChannelData(0);
  const data1 = audioBuffer.getChannelData(1);
  for (let i = 0; i < bufferSize; i++) {
    data0[i] = buf[i * 2];
    data1[i] = buf[i * 2 + 1];
  }
  node.buffer = audioBuffer;
  node.loop = false;
  node.connect(audio.destination);
  node.start(0);
};
</script>
</body>
</html>

