<!DOCTYPE html>
<!-- https://qiita.com/gaziya5/items/e58f8c1fce3f3f227ca7 -->
<html><head><meta charset="utf-8"></head>
<body>
<script id="vs" type="x-shader/x-vertex">
#version 300 es
uniform float sampleRate; 
out vec2 gain; 

#define A 0.125

float noise(float time) {
    return  (fract(sin(time*99.0)*50000.0)*2.0-1.0);
}

float kick(float time) {
    return sin(6.283 * 50.0 * time - 10.0 * exp( -70.0 * time ))*exp(-time*1.6); 
}

float snare(float time) {
  return noise(time)*max(0.0,1.0-min(0.85,time*4.25)-(time-0.25)*0.3);
}

float hihat(float time) {
  return noise(time) * exp(-time * 150.0);
}

float sequence(int s, float time) {
  float n = mod(time, A);
  for (int i=0;i<16;i++){
    if ((s>>(int(time/A)-i)%16&1)==1)
      break;
    n += A;
  }
  return n;
}

vec2 mainSound(float time) {
    return vec2(
                 0.5 * kick(sequence(0x0581, time))+
                 0.3 * snare(sequence(0x1010, time))+
                 0.2 * hihat(sequence(0x5555, time))
                 );
}

void main() {
  float time = float(gl_VertexID) / sampleRate;
  gain = mainSound(time);
}

</script>

<script id="fs" type="x-shader/x-fragment">
#version 300 es
void main() {}
</script>

<button id="btn">start</button>
<script type="module">
btn.onclick = () => {
  const duration = 30; // sec
  const AudioContext = window.AudioContext || window.webkitAudioContext;
  const audio = new AudioContext();
  const sampleRate = audio.sampleRate;
  const bufferSize = (audio.sampleRate * duration) >> 1;
  const audioBuffer = audio.createBuffer(2, bufferSize, audio.sampleRate);
  const node = audio.createBufferSource();
  const canvas = document.createElement("canvas");
  const gl = canvas.getContext("webgl2") || canvas.getContext("experimental-webgl2");
  const compileShader = (prog, src, type) => {
    const sh = gl.createShader(type);
    gl.shaderSource(sh, src.replace(/^\n/, ""));
    gl.compileShader(sh);
    if (!gl.getShaderParameter(sh, gl.COMPILE_STATUS)) {
      alert(gl.getShaderInfoLog(sh));
    } 
    gl.attachShader(prog, sh);
    gl.deleteShader(sh);
  };
  const program = gl.createProgram();
  compileShader(program, vs.text, gl.VERTEX_SHADER);
  compileShader(program, fs.text, gl.FRAGMENT_SHADER);
  gl.transformFeedbackVaryings(program, ['gain'], gl.SEPARATE_ATTRIBS);
  gl.linkProgram(program);
  gl.useProgram(program); 
  gl.uniform1f(gl.getUniformLocation(program, "sampleRate"), sampleRate); 
  const vbos = [gl.createBuffer(),gl.createBuffer()];
  for (let i = 0; i < 2; i++) {
    gl.bindBuffer(gl.ARRAY_BUFFER, vbos[i]);
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(bufferSize * 2), gl.STATIC_DRAW);
  }
  gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, vbos[0]);
  gl.enable(gl.RASTERIZER_DISCARD);
  gl.beginTransformFeedback(gl.POINTS);
  gl.drawArrays(gl.POINTS, 0, bufferSize);
  gl.endTransformFeedback();
  gl.disable(gl.RASTERIZER_DISCARD);
  gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, null);
  gl.bindBuffer(gl.ARRAY_BUFFER, vbos[0]);
  const aryBuffer = new ArrayBuffer(bufferSize * (4 * 2));
  const dataView = new DataView(aryBuffer);
  gl.getBufferSubData(gl.ARRAY_BUFFER, 0, dataView); 
  const buf = new Float32Array(aryBuffer);
  const data0 = audioBuffer.getChannelData(0);
  const data1 = audioBuffer.getChannelData(1);
  for (let i = 0; i < bufferSize; i++) {
    data0[i] = buf[i * 2];
    data1[i] = buf[i * 2 + 1];
  }
  node.buffer = audioBuffer;
  node.loop = false;
  node.connect(audio.destination);
  node.start(0);
};
</script>
</body>
</html>

