<!DOCTYPE html>
<!-- https://qiita.com/gaziya5/items/e58f8c1fce3f3f227ca7 -->
<html><head><meta charset="utf-8"></head>
<body>
<script id="vs" type="x-shader/x-vertex">
#version 300 es
uniform float sampleRate; 
out vec2 gain;

#define BPM 120.
#define A (15./BPM)
#define B (240./BPM)

float sound(float f, float t) {
  float gain = 0.0, a, b = 0.0;
  for(float j = 1.0; j < 8.0; j++){
      b += a = exp(-j *0.5);
      gain +=  a * sin( 6.2831 * f*j*t ) * exp(-t*1.5/(1.0-j*0.1));
  }
  gain *= 1.0 + 1.5*exp(-8.0*t);
  return gain / b;
}

float note2freq(int n) {
    return 440.0*exp2((float(n)-69.0)/12.0);
}

int sequenceOrder(int s, float time) {
    int n =-1;
    for(int i=0;i<=int(mod(time,B)/A);i++){
        if((s>>i&1)==1)n++;
    }
    return n;
}

float sequenceTime(int s,float time) {
  float n = mod(time, A);
  for (int i=0;i<16;i++){
    if((s>>(int(time/A)-i)%16&1)==1)break;
    n+=A;
  }
  return n;
}

#define Scale int[](0,2,4,5,7,9,11,12,14,16,17)
#define Kanon int[](1,5,6,3,4,1,4,5)
#define Key 60

vec2 mainSound( float time ) {
    int b = int(time / B);
    int s = int[](0x5111, 0x1551, 0x5151)[b % 3];
    int o = sequenceOrder(s,time);
    float f = note2freq(Key + Scale[Kanon[b % 8]-1 + o % 3 * 2]);
    return vec2(sound(f,sequenceTime(s, time))) ; 
}

void main() {
  float time = float(gl_VertexID) / sampleRate;
  gain = mainSound(time);
}

</script>

<script id="fs" type="x-shader/x-fragment">
#version 300 es
void main() {}
</script>

<button id="btn">start</button>
<script type="module">
btn.onclick = () => {
  const duration = 38; // sec
  const AudioContext = window.AudioContext || window.webkitAudioContext;
  const audio = new AudioContext();
  const sampleRate = audio.sampleRate;
  const bufferSize = (audio.sampleRate * duration) >> 1;
  const audioBuffer = audio.createBuffer(2, bufferSize, audio.sampleRate);
  const node = audio.createBufferSource();
  const canvas = document.createElement("canvas");
  const gl = canvas.getContext("webgl2") || canvas.getContext("experimental-webgl2");
  const compileShader = (prog, src, type) => {
    const sh = gl.createShader(type);
    gl.shaderSource(sh, src.replace(/^\n/, ""));
    gl.compileShader(sh);
    if (!gl.getShaderParameter(sh, gl.COMPILE_STATUS)) {
      alert(gl.getShaderInfoLog(sh));
    } 
    gl.attachShader(prog, sh);
    gl.deleteShader(sh);
  };
  const program = gl.createProgram();
  compileShader(program, vs.text, gl.VERTEX_SHADER);
  compileShader(program, fs.text, gl.FRAGMENT_SHADER);
  gl.transformFeedbackVaryings(program, ['gain'], gl.SEPARATE_ATTRIBS);
  gl.linkProgram(program);
  gl.useProgram(program); 
  gl.uniform1f(gl.getUniformLocation(program, "sampleRate"), sampleRate); 
  const vbos = [gl.createBuffer(),gl.createBuffer()];
  for (let i = 0; i < 2; i++) {
    gl.bindBuffer(gl.ARRAY_BUFFER, vbos[i]);
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(bufferSize * 2), gl.STATIC_DRAW);
  }
  gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, vbos[0]);
  gl.enable(gl.RASTERIZER_DISCARD);
  gl.beginTransformFeedback(gl.POINTS);
  gl.drawArrays(gl.POINTS, 0, bufferSize);
  gl.endTransformFeedback();
  gl.disable(gl.RASTERIZER_DISCARD);
  gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, null);
  gl.bindBuffer(gl.ARRAY_BUFFER, vbos[0]);
  const aryBuffer = new ArrayBuffer(bufferSize * (4 * 2));
  const dataView = new DataView(aryBuffer);
  gl.getBufferSubData(gl.ARRAY_BUFFER, 0, dataView); 
  const buf = new Float32Array(aryBuffer);
  const data0 = audioBuffer.getChannelData(0);
  const data1 = audioBuffer.getChannelData(1);
  for (let i = 0; i < bufferSize; i++) {
    data0[i] = buf[i * 2];
    data1[i] = buf[i * 2 + 1];
  }
  node.buffer = audioBuffer;
  node.loop = false;
  node.connect(audio.destination);
  node.start(0);
};
</script>
</body>
</html>

